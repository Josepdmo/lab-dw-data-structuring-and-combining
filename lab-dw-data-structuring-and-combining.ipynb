{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {
    "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e"
   },
   "source": [
    "# Lab | Data Structuring and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986",
   "metadata": {
    "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986"
   },
   "source": [
    "## Challenge 1: Combining & Cleaning Data\n",
    "\n",
    "In this challenge, we will be working with the customer data from an insurance company, as we did in the two previous labs. The data can be found here:\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "But this time, we got new data, which can be found in the following 2 CSV files located at the links below.\n",
    "\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\n",
    "\n",
    "Note that you'll need to clean and format the new data.\n",
    "\n",
    "Observation:\n",
    "- One option is to first combine the three datasets and then apply the cleaning function to the new combined dataset\n",
    "- Another option would be to read the clean file you saved in the previous lab, and just clean the two new files and concatenate the three clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "492d06e3-92c7-4105-ac72-536db98d3244",
   "metadata": {
    "id": "492d06e3-92c7-4105-ac72-536db98d3244"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url1 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\"\n",
    "url2 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\"\n",
    "url3 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\"\n",
    "\n",
    "df1 = pd.read_csv(url1)\n",
    "df2 = pd.read_csv(url2)\n",
    "df3 = pd.read_csv(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5303f5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Customer', 'ST', 'GENDER', 'Education', 'Customer Lifetime Value',\n",
      "       'Income', 'Monthly Premium Auto', 'Number of Open Complaints',\n",
      "       'Policy Type', 'Vehicle Class', 'Total Claim Amount'],\n",
      "      dtype='object') Index(['Customer', 'ST', 'GENDER', 'Education', 'Customer Lifetime Value',\n",
      "       'Income', 'Monthly Premium Auto', 'Number of Open Complaints',\n",
      "       'Total Claim Amount', 'Policy Type', 'Vehicle Class'],\n",
      "      dtype='object') Index(['Customer', 'State', 'Customer Lifetime Value', 'Education', 'Gender',\n",
      "       'Income', 'Monthly Premium Auto', 'Number of Open Complaints',\n",
      "       'Policy Type', 'Total Claim Amount', 'Vehicle Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns, df2.columns, df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "195a4bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am making sure that all column names are the same before concating them\n",
    "df1.columns = [i.lower() for i in df1.columns]\n",
    "df1.columns = [i.replace(\" \", \"_\") for i in df1.columns]\n",
    "df2.columns = [i.lower() for i in df2.columns]\n",
    "df2.columns = [i.replace(\" \", \"_\") for i in df2.columns]\n",
    "df3.columns = [i.lower() for i in df3.columns]\n",
    "df3.columns = [i.replace(\" \", \"_\") for i in df3.columns]\n",
    "df3.columns = [i.replace(\"state\", \"st\") for i in df3.columns]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f3c0b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I will concat the different data frames\n",
    "df = pd.concat([df1, df2, df3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6686ab52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer                     2937\n",
       "st                           2937\n",
       "gender                       3059\n",
       "education                    2937\n",
       "customer_lifetime_value      2944\n",
       "income                       2937\n",
       "monthly_premium_auto         2937\n",
       "number_of_open_complaints    2937\n",
       "policy_type                  2937\n",
       "vehicle_class                2937\n",
       "total_claim_amount           2937\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking amount of null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4847eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer                       0\n",
       "st                             0\n",
       "gender                       122\n",
       "education                      0\n",
       "customer_lifetime_value        7\n",
       "income                         0\n",
       "monthly_premium_auto           0\n",
       "number_of_open_complaints      0\n",
       "policy_type                    0\n",
       "vehicle_class                  0\n",
       "total_claim_amount             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting rid of empty rows\n",
    "df.dropna(how = \"all\", axis=0, inplace=True)\n",
    "#Checking amount of null values again\n",
    "df.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ceeb238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer                     0\n",
       "st                           0\n",
       "gender                       0\n",
       "education                    0\n",
       "customer_lifetime_value      7\n",
       "income                       0\n",
       "monthly_premium_auto         0\n",
       "number_of_open_complaints    0\n",
       "policy_type                  0\n",
       "vehicle_class                0\n",
       "total_claim_amount           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will replace NaN in gender by \"not determined\"\n",
    "df.gender.fillna(\"Not determined\", inplace = True)\n",
    "#Check again null values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "78b374f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer                     0\n",
       "st                           0\n",
       "gender                       0\n",
       "education                    0\n",
       "customer_lifetime_value      0\n",
       "income                       0\n",
       "monthly_premium_auto         0\n",
       "number_of_open_complaints    0\n",
       "policy_type                  0\n",
       "vehicle_class                0\n",
       "total_claim_amount           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will eliminate rows that have NaN in customer lifetima value\n",
    "df.dropna(subset = \"customer_lifetime_value\", inplace=True) #removing rows that do not have a customer lifetime value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "56279032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender column contains various inconsistent values such as \"F\", \"M\", \"Femal\", \n",
    "# \"Male\", \"female\", which need to be standardized, for example, to \"M\" and \"F\".\n",
    "gender_mapping = {'Femal': \"F\", 'female': \"F\", \"Male\": \"M\"}\n",
    "df[\"gender\"] = df[\"gender\"].replace(gender_mapping)\n",
    "\n",
    "#*State abbreviations be can replaced with its full name, \n",
    "#for example \"AZ\": \"Arizona\", \"Cali\": \"California\", \"WA\": \"Washington\"*\n",
    "state_mapping = {'AZ': 'Arizona', 'Cali': 'California', 'WA': 'Washington'}\n",
    "df['st'] = df['st'].replace(state_mapping)\n",
    "\n",
    "\n",
    "#In education, \"Bachelors\" could be replaced by \"Bachelor\"\n",
    "education_mapping = {'Bachelors': \"Bachelor\"}\n",
    "df[\"education\"] = df[\"education\"].replace(education_mapping)\n",
    "\n",
    "\n",
    "#In vehicle class, \"Sports Car\", \"Luxury SUV\" and \"Luxury Car\" could be replaced by \"Luxury\"\n",
    "cars_mapping = {\"Sports Car\" : \"Luxury\", \"Luxury SUV\": \"Luxury\", \"Luxury Car\": \"Luxury\"}\n",
    "df[\"vehicle_class\"] = df[\"vehicle_class\"].replace(cars_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bd116103",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CUSTOMER LIFETIME VALUE SHOULD BE NUMERIC\n",
    "#we first convert all elements in the table into strings (otherwise it won't work)\n",
    "df[\"customer_lifetime_value\"] = df[\"customer_lifetime_value\"].astype(str)\n",
    "df[\"customer_lifetime_value\"] = df[\"customer_lifetime_value\"].str.replace(\"%\", \"\").astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c7a5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"number_of_open_complaints\"]=df[\"number_of_open_complaints\"].str.split('/').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c65dcb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"number_of_open_complaints\"]=pd.to_numeric(df['number_of_open_complaints'], errors=\"coerce\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bbae59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check duplicated values\n",
    "df.duplicated().sum()\n",
    "#Drop duplicated values\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5f44faa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8a9e7-7db9-4604-991b-ef6771603e57",
   "metadata": {
    "id": "31b8a9e7-7db9-4604-991b-ef6771603e57"
   },
   "source": [
    "# Challenge 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b",
   "metadata": {
    "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b"
   },
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company, but we will use a dataset with more columns, called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26",
   "metadata": {
    "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10910 entries, 0 to 10909\n",
      "Data columns (total 27 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   unnamed:_0                     10910 non-null  int64  \n",
      " 1   customer                       10910 non-null  object \n",
      " 2   state                          10910 non-null  object \n",
      " 3   customer_lifetime_value        10910 non-null  float64\n",
      " 4   response                       10910 non-null  object \n",
      " 5   coverage                       10910 non-null  object \n",
      " 6   education                      10910 non-null  object \n",
      " 7   effective_to_date              10910 non-null  object \n",
      " 8   employmentstatus               10910 non-null  object \n",
      " 9   gender                         10910 non-null  object \n",
      " 10  income                         10910 non-null  int64  \n",
      " 11  location_code                  10910 non-null  object \n",
      " 12  marital_status                 10910 non-null  object \n",
      " 13  monthly_premium_auto           10910 non-null  int64  \n",
      " 14  months_since_last_claim        10910 non-null  float64\n",
      " 15  months_since_policy_inception  10910 non-null  int64  \n",
      " 16  number_of_open_complaints      10910 non-null  float64\n",
      " 17  number_of_policies             10910 non-null  int64  \n",
      " 18  policy_type                    10910 non-null  object \n",
      " 19  policy                         10910 non-null  object \n",
      " 20  renew_offer_type               10910 non-null  object \n",
      " 21  sales_channel                  10910 non-null  object \n",
      " 22  total_claim_amount             10910 non-null  float64\n",
      " 23  vehicle_class                  10910 non-null  object \n",
      " 24  vehicle_size                   10910 non-null  object \n",
      " 25  vehicle_type                   10910 non-null  object \n",
      " 26  month                          10910 non-null  int64  \n",
      "dtypes: float64(4), int64(6), object(17)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url9 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv\"\n",
    "df4 = pd.read_csv(url9)\n",
    "df4.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35fd0d-513e-4e77-867e-429da10a9cc7",
   "metadata": {
    "id": "df35fd0d-513e-4e77-867e-429da10a9cc7"
   },
   "source": [
    "1. You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, create a summary table showing the total revenue for each sales channel (branch, call center, web, and mail).\n",
    "Round the total revenue to 2 decimal points.  Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640993b2-a291-436c-a34d-a551144f8196",
   "metadata": {
    "id": "640993b2-a291-436c-a34d-a551144f8196"
   },
   "source": [
    "2. Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f2f868e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>policy_type</th>\n",
       "      <th>Corporate Auto</th>\n",
       "      <th>Personal Auto</th>\n",
       "      <th>Special Auto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_channel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Agent</th>\n",
       "      <td>33506545</td>\n",
       "      <td>112569012</td>\n",
       "      <td>6414595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Branch</th>\n",
       "      <td>24113520</td>\n",
       "      <td>84588207</td>\n",
       "      <td>5073881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Call Center</th>\n",
       "      <td>17199770</td>\n",
       "      <td>61136074</td>\n",
       "      <td>2719160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Web</th>\n",
       "      <td>13536670</td>\n",
       "      <td>45884075</td>\n",
       "      <td>2779358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "policy_type    Corporate Auto  Personal Auto  Special Auto\n",
       "sales_channel                                             \n",
       "Agent                33506545      112569012       6414595\n",
       "Branch               24113520       84588207       5073881\n",
       "Call Center          17199770       61136074       2719160\n",
       "Web                  13536670       45884075       2779358"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "df4_piivot = df4.pivot_table(index=\"sales_channel\", columns=\"policy_type\", values=\"income\", aggfunc='sum')\n",
    "df4_piivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "663e1b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>education</th>\n",
       "      <th>Bachelor</th>\n",
       "      <th>College</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>High School or Below</th>\n",
       "      <th>Master</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>7874.269478</td>\n",
       "      <td>7748.823325</td>\n",
       "      <td>7328.508916</td>\n",
       "      <td>8675.220201</td>\n",
       "      <td>8157.053154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>7703.601675</td>\n",
       "      <td>8052.459288</td>\n",
       "      <td>7415.333638</td>\n",
       "      <td>8149.687783</td>\n",
       "      <td>8168.832659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "education     Bachelor      College       Doctor  High School or Below  \\\n",
       "gender                                                                   \n",
       "F          7874.269478  7748.823325  7328.508916           8675.220201   \n",
       "M          7703.601675  8052.459288  7415.333638           8149.687783   \n",
       "\n",
       "education       Master  \n",
       "gender                  \n",
       "F          8157.053154  \n",
       "M          8168.832659  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "df4_pivot=df4.pivot_table(index=\"gender\", columns=\"education\", values=\"customer_lifetime_value\", aggfunc='mean')\n",
    "df4_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7f2e5-3d90-43e5-be33-9781b6069198",
   "metadata": {
    "id": "32c7f2e5-3d90-43e5-be33-9781b6069198"
   },
   "source": [
    "## Bonus\n",
    "\n",
    "You work at the customer service department and you want to know which months had the highest number of complaints by policy type category. Create a summary table showing the number of complaints by policy type and month.\n",
    "Show it in a long format table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291",
   "metadata": {
    "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291"
   },
   "source": [
    "*In data analysis, a long format table is a way of structuring data in which each observation or measurement is stored in a separate row of the table. The key characteristic of a long format table is that each column represents a single variable, and each row represents a single observation of that variable.*\n",
    "\n",
    "*More information about long and wide format tables here: https://www.statology.org/long-vs-wide-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a069e0b-b400-470e-904d-d17582191be4",
   "metadata": {
    "id": "3a069e0b-b400-470e-904d-d17582191be4"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
